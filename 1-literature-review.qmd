# Review the existing models!

## 

![](assets/1-lit-review/the-fig.png){fig-align="center" height="600"}


##

![](assets/1-lit-review/bmj-open.png){.absolute height="200" top="0"}

![](assets/1-lit-review/gerontology.png){.absolute height="400" bottom="0"}


## Objectives

Summarise existing data and methods used to develop inpatient falls prediction models:

  - Sources of data
  - Model development algorithms
  - Evaluation methods
  - Reporting quality

## Included studies

![](assets/1-lit-review/fig-1.png){fig-align="center" height="600"}

## The typical study

Data:

::: {.incremental}

- Available at admission
- Collected via survey/questionnaire
- Variables included previous falls, age, sex, mental state, or physical function assessments
- Case-control sampling to balance fallers and non-fallers

:::

## The typical study

Modelling:

::: {.incremental}
- Logistic regression
- Predictions made at or soon after admission
- Outcome: one or more falls during admission

:::

## The typical study

::: {.incremental}

Validation methods:

- Bad

Reporting: 

- Worse

:::

## Sample sizes

![](assets/1-lit-review/fig-2-sample-sizes.jpeg){fig-align="center" height="450"}

## Reporting

![](assets/1-lit-review/fig-3-tripod.jpeg){fig-align="center" height="450"}


## The not-so-typical

- Two studies predicted falls within the next 24-hour period and made new predictions each day of admission^1^
- Considered relative cost of false negatives to false positives to select prediction model cutpoint^2^

::: footer
^1^ Yokota (2016) and Yokota (2017)<br>
^2^ Marschollek (2012)
:::


## Gaps

- Almost no use of time-to-event models to estimate falls risk
- Almost no models updated throughout admission or whenever new data is available
- Relatively few studies relied solely on routine, electronic data
